{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "        self.conv=nn.Sequential(\n",
    "            nn.Conv2d(1,96,11,4),#in_channels, out_channels, kernel_size, stride, padding\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3,2),# kernel_size, stride\n",
    "            # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n",
    "            nn.Conv2d(96, 256, 5, 1, 2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2),\n",
    "            # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n",
    "            # 前两个卷积层后不使用池化层来减小输入的高和宽\n",
    "            nn.Conv2d(256, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 384, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(384, 256, 3, 1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(3, 2)\n",
    "        )\n",
    "         # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256*5*5, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n",
    "            nn.Linear(4096, 10),\n",
    "        )\n",
    "    def forward(self, img):\n",
    "        feature = self.conv(img)\n",
    "        output = self.fc(feature.view(img.shape[0], -1))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(1, 96, kernel_size=(11, 11), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU()\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU()\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = AlexNet()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个可以通过torchvision.transforms.Resize实例来实现。也就是说，我们在ToTensor实例前使用Resize实例，然后使用Compose实例来将这两个变换串联以方便调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def load_data_fashion_mnist(batch_size, resize=None, root='./fashion-mnist-master/data/fashion/'):\n",
    "    trans=[]\n",
    "    if resize:\n",
    "        trans.append(torchvision.transforms.Resize(size=resize))\n",
    "    trans.append(torchvision.transforms.ToTensor())\n",
    "    transform=torchvision.transforms.Compose(trans)\n",
    "    mnist_train=torchvision.datasets.FashionMNIST(root=root,train=True,download=True,transform=transform)\n",
    "    mnist_test=torchvision.datasets.FashionMNIST(root=root,train=False,download=True,transform=transform)\n",
    "    train_iter=torch.utils.data.DataLoader(mnist_train,batch_size=batch_size,shuffle=True, num_workers=4)\n",
    "    test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    return train_iter, test_iter\n",
    "\n",
    "batch_size = 128\n",
    "# 如出现“out of memory”的报错信息，可减小batch_size或resize\n",
    "train_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用。该函数将被逐步改进。\n",
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        # 如果没指定device就使用net的device\n",
    "        device = list(net.parameters())[0].device\n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval() # 评估模式, 这会关闭dropout\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train() # 改回训练模式\n",
    "            else: # 自定义的模型, 3.13节之后不会用到, 不考虑GPU\n",
    "                if('is_training' in net.__code__.co_varnames): # 如果有is_training这个参数\n",
    "                    # 将is_training设置成False\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    #先把网络放到gpu上\n",
    "    net=net.to(device)\n",
    "    print('training on ',device)\n",
    "    #选择损失函数\n",
    "    loss=torch.nn.CrossEntropyLoss()\n",
    "    #开始迭代\n",
    "    for epoch in range(num_epochs):\n",
    "        print(epoch)\n",
    "        loss_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X,y in train_iter:#讲值和value取出来\n",
    "            #放到gpu上\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            #开始训练net\n",
    "            y_hat=net(X)\n",
    "            #loss计算损失\n",
    "            los=loss(y_hat,y)\n",
    "            #梯度清0\n",
    "            optimizer.zero_grad()\n",
    "            #反向传播\n",
    "            los.backward()\n",
    "            #递进\n",
    "            optimizer.step()\n",
    "            loss_sum+=los.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "        test_acc=evaluate_accuracy(test_iter,net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, loss_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def train_ch5(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs):\n",
    "    net=net.to(device)\n",
    "    print('training in ',device)\n",
    "    loss=torch.nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, batch_count, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X=X.to(device)\n",
    "            y=y.to(device)\n",
    "            y_hat=net(X)\n",
    "            los=loss(y_hat,y)\n",
    "            optimizer.zero_grad()\n",
    "            los.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum+=los.cpu().item()\n",
    "            train_acc_sum+=(y_hat.argmax(dim=1)==y).sum().cpu().item()\n",
    "            n+=y.shape[0]\n",
    "            batch_count+=1\n",
    "            print(train_l_sum,train_acc_sum,n,batch_count)\n",
    "        test_acc=evaluate_accuracy(test_iter,net,device)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training in  cpu\n",
      "2.3023953437805176 15.0 128 1\n",
      "5.6565821170806885 22.0 256 2\n",
      "7.957902908325195 36.0 384 3\n",
      "10.273881435394287 51.0 512 4\n",
      "12.576133966445923 63.0 640 5\n",
      "14.87347149848938 85.0 768 6\n",
      "17.16584801673889 113.0 896 7\n",
      "19.419498205184937 141.0 1024 8\n",
      "21.669912815093994 166.0 1152 9\n",
      "23.755313873291016 209.0 1280 10\n",
      "25.91893434524536 229.0 1408 11\n",
      "28.063246965408325 255.0 1536 12\n",
      "29.95831549167633 293.0 1664 13\n",
      "31.70894718170166 338.0 1792 14\n",
      "33.70026433467865 362.0 1920 15\n",
      "35.47566568851471 388.0 2048 16\n",
      "37.11723291873932 425.0 2176 17\n",
      "38.737133622169495 467.0 2304 18\n",
      "40.271469473838806 510.0 2432 19\n",
      "41.75378942489624 559.0 2560 20\n",
      "43.59892237186432 606.0 2688 21\n",
      "44.90757930278778 655.0 2816 22\n",
      "46.24867522716522 707.0 2944 23\n",
      "47.81017708778381 757.0 3072 24\n",
      "49.1345648765564 827.0 3200 25\n",
      "50.4449862241745 888.0 3328 26\n",
      "51.83617281913757 947.0 3456 27\n",
      "53.15341782569885 1012.0 3584 28\n",
      "54.39394986629486 1078.0 3712 29\n",
      "55.792675375938416 1135.0 3840 30\n",
      "56.990732312202454 1203.0 3968 31\n",
      "58.119770765304565 1263.0 4096 32\n",
      "59.43106770515442 1318.0 4224 33\n",
      "60.578946590423584 1379.0 4352 34\n",
      "61.81353044509888 1446.0 4480 35\n",
      "62.95639193058014 1502.0 4608 36\n",
      "64.09017586708069 1561.0 4736 37\n",
      "65.29316627979279 1626.0 4864 38\n",
      "66.36439538002014 1697.0 4992 39\n",
      "67.4485536813736 1773.0 5120 40\n",
      "68.46686506271362 1850.0 5248 41\n",
      "69.46303993463516 1934.0 5376 42\n",
      "70.61552375555038 2006.0 5504 43\n",
      "71.75576585531235 2074.0 5632 44\n",
      "72.72609895467758 2145.0 5760 45\n",
      "73.69647371768951 2225.0 5888 46\n",
      "74.68972390890121 2291.0 6016 47\n",
      "75.74892979860306 2367.0 6144 48\n",
      "76.73765182495117 2429.0 6272 49\n",
      "77.62770074605942 2500.0 6400 50\n",
      "78.54230666160583 2584.0 6528 51\n",
      "79.63039529323578 2661.0 6656 52\n",
      "80.41325348615646 2745.0 6784 53\n",
      "81.41574758291245 2823.0 6912 54\n",
      "82.26582646369934 2907.0 7040 55\n",
      "83.14567017555237 2992.0 7168 56\n",
      "84.12278699874878 3078.0 7296 57\n",
      "84.96400201320648 3170.0 7424 58\n",
      "85.88511669635773 3254.0 7552 59\n",
      "86.81243127584457 3332.0 7680 60\n",
      "87.85320442914963 3408.0 7808 61\n",
      "88.67802011966705 3491.0 7936 62\n",
      "89.63508981466293 3569.0 8064 63\n",
      "90.54411196708679 3652.0 8192 64\n",
      "91.41411244869232 3738.0 8320 65\n",
      "92.3542971611023 3820.0 8448 66\n",
      "93.15292143821716 3910.0 8576 67\n",
      "94.18921041488647 3992.0 8704 68\n",
      "95.0503716468811 4074.0 8832 69\n",
      "95.9474111199379 4154.0 8960 70\n",
      "96.62449491024017 4245.0 9088 71\n",
      "97.37497764825821 4332.0 9216 72\n",
      "98.23910439014435 4419.0 9344 73\n",
      "99.07641500234604 4501.0 9472 74\n",
      "99.79223901033401 4592.0 9600 75\n",
      "100.48297894001007 4684.0 9728 76\n",
      "101.4357088804245 4771.0 9856 77\n",
      "102.32987141609192 4855.0 9984 78\n",
      "102.9668231010437 4956.0 10112 79\n",
      "103.76964920759201 5039.0 10240 80\n",
      "104.41885560750961 5139.0 10368 81\n",
      "105.18567490577698 5229.0 10496 82\n",
      "106.02994966506958 5316.0 10624 83\n",
      "106.80127382278442 5404.0 10752 84\n",
      "107.59360754489899 5498.0 10880 85\n",
      "108.28559982776642 5590.0 11008 86\n",
      "109.01242244243622 5685.0 11136 87\n",
      "109.90452933311462 5774.0 11264 88\n",
      "110.56994688510895 5872.0 11392 89\n",
      "111.19282650947571 5972.0 11520 90\n",
      "111.78892683982849 6066.0 11648 91\n",
      "112.36596810817719 6168.0 11776 92\n",
      "113.02795535326004 6267.0 11904 93\n",
      "113.63497871160507 6362.0 12032 94\n",
      "114.29295134544373 6459.0 12160 95\n",
      "114.94198715686798 6556.0 12288 96\n",
      "115.49211138486862 6657.0 12416 97\n",
      "116.22306197881699 6745.0 12544 98\n",
      "116.86841762065887 6837.0 12672 99\n",
      "117.43584161996841 6940.0 12800 100\n",
      "117.99564957618713 7043.0 12928 101\n",
      "118.51525765657425 7142.0 13056 102\n",
      "119.11659950017929 7238.0 13184 103\n",
      "119.84899961948395 7336.0 13312 104\n",
      "120.55697458982468 7428.0 13440 105\n",
      "121.12398910522461 7527.0 13568 106\n",
      "121.94864505529404 7619.0 13696 107\n",
      "122.68857580423355 7714.0 13824 108\n",
      "123.3426570892334 7816.0 13952 109\n",
      "123.87522792816162 7923.0 14080 110\n",
      "124.53083127737045 8021.0 14208 111\n",
      "125.17086398601532 8120.0 14336 112\n",
      "125.85339498519897 8214.0 14464 113\n",
      "126.30628642439842 8321.0 14592 114\n",
      "126.89914813637733 8417.0 14720 115\n",
      "127.41805866360664 8517.0 14848 116\n",
      "128.08699026703835 8610.0 14976 117\n",
      "128.70585152506828 8706.0 15104 118\n",
      "129.2040862441063 8810.0 15232 119\n",
      "129.7840477824211 8909.0 15360 120\n",
      "130.34607201814651 9006.0 15488 121\n",
      "130.9443947672844 9101.0 15616 122\n",
      "131.5727607011795 9203.0 15744 123\n",
      "132.07722824811935 9309.0 15872 124\n",
      "132.73687261343002 9403.0 16000 125\n",
      "133.32728278636932 9499.0 16128 126\n",
      "133.85078537464142 9602.0 16256 127\n",
      "134.4562342762947 9701.0 16384 128\n",
      "134.97936183214188 9803.0 16512 129\n",
      "135.52372819185257 9901.0 16640 130\n",
      "136.1211074590683 9998.0 16768 131\n",
      "136.7958766222 10092.0 16896 132\n",
      "137.47479128837585 10182.0 17024 133\n",
      "137.92579647898674 10286.0 17152 134\n",
      "138.43583819270134 10387.0 17280 135\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "# train(net, train_iter, test_iter, batch_size, optimizer, device, num_epochs)\n",
    "train_ch5(net,train_iter,test_iter,batch_size,optimizer,device,num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
