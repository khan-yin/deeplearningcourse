{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import torchvision.transforms as transforms\n",
    "import d2lzh_pytorch as d2l\n",
    "import torchvision \n",
    "from torch.utils.data.dataset import Dataset\n",
    "import os\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    data_folder: 文件目录\n",
    "    data_name： 数据文件名\n",
    "    label_name：标签数据文件名\n",
    "\"\"\"\n",
    "\n",
    "def load_data(data_folder, data_name, label_name):\n",
    "    with gzip.open(os.path.join(data_folder,label_name), 'rb') as lbpath: # rb表示的是读取二进制数据\n",
    "        y_train = np.frombuffer(lbpath.read(), np.uint8, offset=8)\n",
    "\n",
    "    with gzip.open(os.path.join(data_folder,data_name), 'rb') as imgpath:\n",
    "        x_train = np.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)\n",
    "    return (x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DealDataset(Dataset):\n",
    "    \"\"\"\n",
    "        读取数据、初始化数据\n",
    "    \"\"\"\n",
    "    def __init__(self, folder, data_name, label_name,transform=None):\n",
    "        (train_set, train_labels) = load_data(folder, data_name, label_name) # 其实也可以直接使用torch.load(),读取之后的结果为torch.Tensor形式\n",
    "        self.train_set = train_set\n",
    "        self.train_labels = train_labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        img, target = self.train_set[index], int(self.train_labels[index])\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = DealDataset('./fashion-mnist-master/data/fashion/', \"train-images-idx3-ubyte.gz\",\"train-labels-idx1-ubyte.gz\",transform=transforms.ToTensor())\n",
    "mnist_test = DealDataset('./fashion-mnist-master/data/fashion/', \"t10k-images-idx3-ubyte.gz\",\"t10k-labels-idx1-ubyte.gz\",transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "if sys.platform.startswith('win'):\n",
    "    num_workers = 0  # 0表示不用额外的进程来加速读取数据\n",
    "else:\n",
    "    num_workers = 4\n",
    "train_iter = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_iter = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型  \n",
    "和softmax回归唯一的不同在于，我们多加了一个全连接层作为隐藏层。它的隐藏单元个数为256，并使用ReLU函数作为激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
    "\n",
    "net = nn.Sequential(\n",
    "        d2l.FlattenLayer(),\n",
    "        nn.Linear(num_inputs, num_hiddens),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(num_hiddens, num_outputs), \n",
    "        )\n",
    "\n",
    "for params in net.parameters():\n",
    "    init.normal_(params, mean=0, std=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并训练模型  \n",
    "注：由于这里使用的是PyTorch的SGD而不是d2lzh_pytorch里面的sgd，所以就不存在3.9节那样学习率看起来很大的问题了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.0030, train acc 0.709, test acc 0.744\n",
      "epoch 2, loss 0.0019, train acc 0.817, test acc 0.824\n",
      "epoch 3, loss 0.0016, train acc 0.845, test acc 0.836\n",
      "epoch 4, loss 0.0015, train acc 0.856, test acc 0.842\n",
      "epoch 5, loss 0.0014, train acc 0.865, test acc 0.851\n"
     ]
    }
   ],
   "source": [
    "#定义损失函数\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.5)\n",
    "\n",
    "num_epochs = 5\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, None, None, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
