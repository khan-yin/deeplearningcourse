{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "。这里我们介绍其中的一种方法：它以每个像素为中心生成多个大小和宽高比（aspect ratio）不同的边界框"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4.0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\") \n",
    "import d2lzh_pytorch as d2l\n",
    "print(torch.__version__) # 1.2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "# 参考https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L356\n",
    "def compute_intersection(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的交集\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
    "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
    "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
    "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
    "\n",
    "\n",
    "def compute_jaccard(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的Jaccard系数(IoU)\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # Find intersections\n",
    "    intersection = compute_intersection(set_1, set_2)  # (n1, n2)\n",
    "\n",
    "    # Find areas of each box in both sets\n",
    "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
    "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
    "\n",
    "    # Find the union\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
    "\n",
    "    return intersection / union  # (n1, n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "# 参考https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py#L356\n",
    "def compute_intersection(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的交集\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        intersection of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    lower_bounds = torch.max(set_1[:, :2].unsqueeze(1), set_2[:, :2].unsqueeze(0))  # (n1, n2, 2)\n",
    "    upper_bounds = torch.min(set_1[:, 2:].unsqueeze(1), set_2[:, 2:].unsqueeze(0))  # (n1, n2, 2)\n",
    "    intersection_dims = torch.clamp(upper_bounds - lower_bounds, min=0)  # (n1, n2, 2)\n",
    "    return intersection_dims[:, :, 0] * intersection_dims[:, :, 1]  # (n1, n2)\n",
    "\n",
    "\n",
    "def compute_jaccard(set_1, set_2):\n",
    "    \"\"\"\n",
    "    计算anchor之间的Jaccard系数(IoU)\n",
    "    Args:\n",
    "        set_1: a tensor of dimensions (n1, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "        set_2: a tensor of dimensions (n2, 4), anchor表示成(xmin, ymin, xmax, ymax)\n",
    "    Returns:\n",
    "        Jaccard Overlap of each of the boxes in set 1 with respect to each of the boxes in set 2, shape: (n1, n2)\n",
    "    \"\"\"\n",
    "    # Find intersections\n",
    "    intersection = compute_intersection(set_1, set_2)  # (n1, n2)\n",
    "\n",
    "    # Find areas of each box in both sets\n",
    "    areas_set_1 = (set_1[:, 2] - set_1[:, 0]) * (set_1[:, 3] - set_1[:, 1])  # (n1)\n",
    "    areas_set_2 = (set_2[:, 2] - set_2[:, 0]) * (set_2[:, 3] - set_2[:, 1])  # (n2)\n",
    "\n",
    "    # Find the union\n",
    "    # PyTorch auto-broadcasts singleton dimensions\n",
    "    union = areas_set_1.unsqueeze(1) + areas_set_2.unsqueeze(0) - intersection  # (n1, n2)\n",
    "\n",
    "    return intersection / union  # (n1, n2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'w' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f4d116b3190f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbbox_scale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m ground_truth = torch.tensor([[0, 0.1, 0.08, 0.52, 0.92],\n\u001b[0;32m      3\u001b[0m                             [1, 0.55, 0.2, 0.9, 0.88]])\n\u001b[0;32m      4\u001b[0m anchors = torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4],\n\u001b[0;32m      5\u001b[0m                     \u001b[1;33m[\u001b[0m\u001b[1;36m0.63\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.88\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.98\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.66\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.45\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'w' is not defined"
     ]
    }
   ],
   "source": [
    "bbox_scale = torch.tensor((w, h, w, h), dtype=torch.float32)\n",
    "ground_truth = torch.tensor([[0, 0.1, 0.08, 0.52, 0.92],\n",
    "                            [1, 0.55, 0.2, 0.9, 0.88]])\n",
    "anchors = torch.tensor([[0, 0.1, 0.2, 0.3], [0.15, 0.2, 0.4, 0.4],\n",
    "                    [0.63, 0.05, 0.88, 0.98], [0.66, 0.45, 0.8, 0.8],\n",
    "                    [0.57, 0.3, 0.92, 0.9]])\n",
    "\n",
    "fig = d2l.plt.imshow(img)\n",
    "show_bboxes(fig.axes, ground_truth[:, 1:] * bbox_scale, ['dog', 'cat'], 'k')\n",
    "show_bboxes(fig.axes, anchors * bbox_scale, ['0', '1', '2', '3', '4']);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下函数已保存在d2lzh_pytorch包中方便以后使用\n",
    "def assign_anchor(bb, anchor, jaccard_threshold=0.5):\n",
    "    \"\"\"\n",
    "    # 按照「9.4.1. 生成多个锚框」图9.3所讲为每个anchor分配真实的bb, anchor表示成归一化(xmin, ymin, xmax, ymax).\n",
    "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\n",
    "    Args:\n",
    "        bb: 真实边界框(bounding box), shape:（nb, 4）\n",
    "        anchor: 待分配的anchor, shape:（na, 4）\n",
    "        jaccard_threshold: 预先设定的阈值\n",
    "    Returns:\n",
    "        assigned_idx: shape: (na, ), 每个anchor分配的真实bb对应的索引, 若未分配任何bb则为-1\n",
    "    \"\"\"\n",
    "    na = anchor.shape[0]\n",
    "    nb = bb.shape[0]\n",
    "    jaccard = compute_jaccard(anchor, bb).detach().cpu().numpy() # shape: (na, nb)\n",
    "    assigned_idx = np.ones(na) * -1  # 初始全为-1\n",
    "\n",
    "    # 先为每个bb分配一个anchor(不要求满足jaccard_threshold)\n",
    "    jaccard_cp = jaccard.copy()\n",
    "    for j in range(nb):\n",
    "        i = np.argmax(jaccard_cp[:, j])\n",
    "        assigned_idx[i] = j\n",
    "        jaccard_cp[i, :] = float(\"-inf\") # 赋值为负无穷, 相当于去掉这一行\n",
    "\n",
    "    # 处理还未被分配的anchor, 要求满足jaccard_threshold\n",
    "    for i in range(na):\n",
    "        if assigned_idx[i] == -1:\n",
    "            j = np.argmax(jaccard[i, :])\n",
    "            if jaccard[i, j] >= jaccard_threshold:\n",
    "                assigned_idx[i] = j\n",
    "\n",
    "    return torch.tensor(assigned_idx, dtype=torch.long)\n",
    "\n",
    "def xy_to_cxcy(xy):\n",
    "    \"\"\"\n",
    "    将(x_min, y_min, x_max, y_max)形式的anchor转换成(center_x, center_y, w, h)形式的.\n",
    "    https://github.com/sgrvinod/a-PyTorch-Tutorial-to-Object-Detection/blob/master/utils.py\n",
    "    Args:\n",
    "        xy: bounding boxes in boundary coordinates, a tensor of size (n_boxes, 4)\n",
    "    Returns: \n",
    "        bounding boxes in center-size coordinates, a tensor of size (n_boxes, 4)\n",
    "    \"\"\"\n",
    "    return torch.cat([(xy[:, 2:] + xy[:, :2]) / 2,  # c_x, c_y\n",
    "                      xy[:, 2:] - xy[:, :2]], 1)  # w, h\n",
    "\n",
    "def MultiBoxTarget(anchor, label):\n",
    "    \"\"\"\n",
    "    # 按照「9.4.1. 生成多个锚框」所讲的实现, anchor表示成归一化(xmin, ymin, xmax, ymax).\n",
    "    https://zh.d2l.ai/chapter_computer-vision/anchor.html\n",
    "    Args:\n",
    "        anchor: torch tensor, 输入的锚框, 一般是通过MultiBoxPrior生成, shape:（1，锚框总数，4）\n",
    "        label: 真实标签, shape为(bn, 每张图片最多的真实锚框数, 5)\n",
    "               第二维中，如果给定图片没有这么多锚框, 可以先用-1填充空白, 最后一维中的元素为[类别标签, 四个坐标值]\n",
    "    Returns:\n",
    "        列表, [bbox_offset, bbox_mask, cls_labels]\n",
    "        bbox_offset: 每个锚框的标注偏移量，形状为(bn，锚框总数*4)\n",
    "        bbox_mask: 形状同bbox_offset, 每个锚框的掩码, 一一对应上面的偏移量, 负类锚框(背景)对应的掩码均为0, 正类锚框的掩码均为1\n",
    "        cls_labels: 每个锚框的标注类别, 其中0表示为背景, 形状为(bn，锚框总数)\n",
    "    \"\"\"\n",
    "    assert len(anchor.shape) == 3 and len(label.shape) == 3\n",
    "    bn = label.shape[0]\n",
    "\n",
    "    def MultiBoxTarget_one(anc, lab, eps=1e-6):\n",
    "        \"\"\"\n",
    "        MultiBoxTarget函数的辅助函数, 处理batch中的一个\n",
    "        Args:\n",
    "            anc: shape of (锚框总数, 4)\n",
    "            lab: shape of (真实锚框数, 5), 5代表[类别标签, 四个坐标值]\n",
    "            eps: 一个极小值, 防止log0\n",
    "        Returns:\n",
    "            offset: (锚框总数*4, )\n",
    "            bbox_mask: (锚框总数*4, ), 0代表背景, 1代表非背景\n",
    "            cls_labels: (锚框总数, 4), 0代表背景\n",
    "        \"\"\"\n",
    "        an = anc.shape[0]\n",
    "        assigned_idx = assign_anchor(lab[:, 1:], anc) # (锚框总数, )\n",
    "        bbox_mask = ((assigned_idx >= 0).float().unsqueeze(-1)).repeat(1, 4) # (锚框总数, 4)\n",
    "\n",
    "        cls_labels = torch.zeros(an, dtype=torch.long) # 0表示背景\n",
    "        assigned_bb = torch.zeros((an, 4), dtype=torch.float32) # 所有anchor对应的bb坐标\n",
    "        for i in range(an):\n",
    "            bb_idx = assigned_idx[i]\n",
    "            if bb_idx >= 0: # 即非背景\n",
    "                cls_labels[i] = lab[bb_idx, 0].long().item() + 1 # 注意要加一\n",
    "                assigned_bb[i, :] = lab[bb_idx, 1:]\n",
    "\n",
    "        center_anc = xy_to_cxcy(anc) # (center_x, center_y, w, h)\n",
    "        center_assigned_bb = xy_to_cxcy(assigned_bb)\n",
    "\n",
    "        offset_xy = 10.0 * (center_assigned_bb[:, :2] - center_anc[:, :2]) / center_anc[:, 2:]\n",
    "        offset_wh = 5.0 * torch.log(eps + center_assigned_bb[:, 2:] / center_anc[:, 2:])\n",
    "        offset = torch.cat([offset_xy, offset_wh], dim = 1) * bbox_mask # (锚框总数, 4)\n",
    "\n",
    "        return offset.view(-1), bbox_mask.view(-1), cls_labels\n",
    "\n",
    "    batch_offset = []\n",
    "    batch_mask = []\n",
    "    batch_cls_labels = []\n",
    "    for b in range(bn):\n",
    "        offset, bbox_mask, cls_labels = MultiBoxTarget_one(anchor[0, :, :], label[b, :, :])\n",
    "\n",
    "        batch_offset.append(offset)\n",
    "        batch_mask.append(bbox_mask)\n",
    "        batch_cls_labels.append(cls_labels)\n",
    "\n",
    "    bbox_offset = torch.stack(batch_offset)\n",
    "    bbox_mask = torch.stack(batch_mask)\n",
    "    cls_labels = torch.stack(batch_cls_labels)\n",
    "\n",
    "    return [bbox_offset, bbox_mask, cls_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'anchors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f2e7cf455c88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m labels = MultiBoxTarget(anchors.unsqueeze(dim=0),\n\u001b[0m\u001b[0;32m      2\u001b[0m                         ground_truth.unsqueeze(dim=0))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'anchors' is not defined"
     ]
    }
   ],
   "source": [
    "labels = MultiBoxTarget(anchors.unsqueeze(dim=0),\n",
    "                        ground_truth.unsqueeze(dim=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
